@inproceedings{zhao2021ethical,
    title={Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?},
    author={Jieyu Zhao and Daniel Khashabi and Tushar Khot and Ashish Sabharwal and Kai-Wei Chang},
    rank = {33},
    booktitle={ACL-Finding (short)},
    paper_url={https://arxiv.org/abs/2106.01465},
    tweet={https://twitter.com/jieyuzhao11/status/1401041612621312000}, 
    abstract={Is it possible to use natural language to intervene in a model's behavior and alter its prediction in a desired way? We investigate the effectiveness of natural language interventions for reading-comprehension systems, studying this in the context of social stereotypes. Specifically, we propose a new language understanding task, Linguistic Ethical Interventions (LEI), where the goal is to amend a question-answering (QA) model's unethical behavior by communicating context-specific principles of ethics and equity to it. To this end, we build upon recent methods for quantifying a system's social stereotypes, augmenting them with different kinds of ethical interventions and the desired model behavior under such interventions. Our zero-shot evaluation finds that even today's powerful neural language models are extremely poor ethical-advice takers, that is, they respond surprisingly little to ethical interventions even though these interventions are stated as simple sentences. Few-shot learning improves model behavior but remains far from the desired outcome, especially when evaluated for various types of generalization. Our new task thus poses a novel language understanding challenge for the community.},
    year={2021}
}